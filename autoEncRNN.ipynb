{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "# from rdkit import Chem\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdkit load SMILES and structures\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 120\n",
    "\n",
    "dset_path = 'dataset'\n",
    "esol_dset_path = os.path.join(dset_path, 'ESOL')\n",
    "esol_dset = os.path.join(esol_dset_path, 'delaney-processed.csv')\n",
    "zinc_dset = os.path.join(dset_path, '250k_rndm_zinc_drugs_clean_3.csv')\n",
    "\n",
    "# ESOL Dataset\n",
    "esol_df = pd.read_csv(esol_dset)\n",
    "esol_solu_df = esol_df[['smiles', 'measured log solubility in mols per litre']]\n",
    "# esol_solu_df['mols'] = esol_solu_df.apply(lambda x: Chem.MolFromSmiles(x.smiles), axis=1)\n",
    "\n",
    "# VAE Dataset\n",
    "zinc_df = pd.read_csv(zinc_dset, index_col=None)\n",
    "zinc_df = zinc_df.replace('\\n', '', regex=True)\n",
    "# zinc_df['mols'] = zinc_df.apply(lambda x: Chem.MolFromSmiles(x.smiles), axis=1)\n",
    "\n",
    "# # ----------One hot SMILES----------\n",
    "# from deepchem.feat.one_hot import OneHotFeaturizer, zinc_charset\n",
    "# featurizer_onehot = OneHotFeaturizer(zinc_charset, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elem:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSMILES(self, smiles):\n",
    "        elements = list(smiles.strip())\n",
    "        for element in elements:\n",
    "            self.addElement(element)\n",
    "\n",
    "    def addElement(self, element):\n",
    "        if element not in self.word2index:\n",
    "            self.word2index[element] = self.n_words\n",
    "            self.word2count[element] = 1\n",
    "            self.index2word[self.n_words] = element\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[element] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 249455 sentence pairs\n",
      "Trimmed to 249455 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "input_elem 36\n",
      "output_elem 36\n",
      "['Cc1ccc(NC(=O)c2nn3ccccc3c2Cl)cc1C', 3.85684]\n"
     ]
    }
   ],
   "source": [
    "def prepareSMILES(SMILES_arr, properties):\n",
    "    input_elem, output_elem, pairs = Elem('input_elem'), Elem('output_elem'), [[i, j] for i, j in zip(SMILES_arr, properties)]\n",
    "    print(\"Read %s sentence pairs\" % len(SMILES_arr))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_elem.addSMILES(pair[0])\n",
    "        output_elem.addSMILES(pair[0])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_elem.name, input_elem.n_words)\n",
    "    print(output_elem.name, output_elem.n_words)\n",
    "    return input_elem, output_elem, pairs\n",
    "\n",
    "# input_elem, output_elem, pairs = prepareSMILES(esol_df['smiles'].values, esol_df['measured log solubility in mols per litre'].values)\n",
    "input_elem, output_elem, pairs = prepareSMILES(zinc_df['smiles'].values, zinc_df['logP'].values)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(elem, smiles):\n",
    "    return [elem.word2index[element] for element in list(smiles.strip())]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, smiles):\n",
    "    indexes = indexesFromSentence(lang, smiles)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_elem, pair[0])\n",
    "    target_tensor = torch.tensor(pair[1], dtype=torch.long, device=device).view(-1)\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(tensor_pairs, train_size_percentage=0.8, BATCH_SIZE=1):\n",
    "    train_size = int(train_size_percentage * len(tensor_pairs))\n",
    "    test_size = len(tensor_pairs) - train_size\n",
    "    train_dset, test_dset = random_split([tensorsFromPair(pair) for pair in tensor_pairs], [train_size, test_size])\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_dset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "#             decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "#             decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, training_loader, print_every=1000, plot_every=100, learning_rate=0.01, EPOCH=50, model_folder='test'):\n",
    "    if not os.path.exists('./model/' + model_folder):\n",
    "        os.mkdir('./model/' + model_folder)\n",
    "\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate) # SGD\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate) # SGD\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, EPOCH + 1):\n",
    "        print('Time info:', timeSince(start, epoch / EPOCH))\n",
    "        for batch_idx, (data, target) in enumerate(training_loader):\n",
    "            batch_idx += 1\n",
    "            # training_pair = training_pairs[iter - 1]\n",
    "            input_tensor, target_tensor = data[0], data[0]\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if batch_idx % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                # (timeSince(start, iter / n_iters)\n",
    "                # print('Iter: {}/{} ({:.0f}%)\\tLoss: {:.6f}'.format(iter, n_iters, iter / n_iters * 100, print_loss_avg))\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                    print_loss_avg))\n",
    "\n",
    "            if batch_idx % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "        # Save model/parameters\n",
    "        torch.save(encoder.state_dict(), './model/{}/model_autoencRNN_enc_{}.pkl'.format(model_folder, epoch))\n",
    "        torch.save(decoder.state_dict(), './model/{}/model_autoencRNN_dec_{}.pkl'.format(model_folder, epoch))\n",
    "        if epoch == (EPOCH - 1):\n",
    "            torch.save(encoder, './model/{}/model_autoencRNN_enc_{}.pkl'.format(model_folder, epoch))\n",
    "            torch.save(decoder, './model/{}/model_autoencRNN_dec_{}.pkl'.format(model_folder, epoch))\n",
    "\n",
    "    # showPlot(plot_losses)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_elem, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "#             decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "#             decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_elem.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ''.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info: 0m 0s (- 0m 0s)\n",
      "Train Epoch: 1 [10000/199564 (5%)]\tLoss: 1.967505\n",
      "Train Epoch: 1 [20000/199564 (10%)]\tLoss: 1.617651\n",
      "Train Epoch: 1 [30000/199564 (15%)]\tLoss: 1.434214\n",
      "Train Epoch: 1 [40000/199564 (20%)]\tLoss: 1.341145\n",
      "Train Epoch: 1 [50000/199564 (25%)]\tLoss: 1.270349\n",
      "Train Epoch: 1 [60000/199564 (30%)]\tLoss: 1.240017\n",
      "Train Epoch: 1 [70000/199564 (35%)]\tLoss: 1.191389\n",
      "Train Epoch: 1 [80000/199564 (40%)]\tLoss: 1.172250\n",
      "Train Epoch: 1 [90000/199564 (45%)]\tLoss: 1.164519\n",
      "Train Epoch: 1 [100000/199564 (50%)]\tLoss: 1.153748\n",
      "Train Epoch: 1 [110000/199564 (55%)]\tLoss: 1.115040\n",
      "Train Epoch: 1 [120000/199564 (60%)]\tLoss: 1.108262\n",
      "Train Epoch: 1 [130000/199564 (65%)]\tLoss: 1.118200\n",
      "Train Epoch: 1 [140000/199564 (70%)]\tLoss: 1.104337\n",
      "Train Epoch: 1 [150000/199564 (75%)]\tLoss: 1.096067\n",
      "Train Epoch: 1 [160000/199564 (80%)]\tLoss: 1.107780\n",
      "Train Epoch: 1 [170000/199564 (85%)]\tLoss: 1.153953\n",
      "Train Epoch: 1 [180000/199564 (90%)]\tLoss: 1.135784\n",
      "Train Epoch: 1 [190000/199564 (95%)]\tLoss: 1.130145\n",
      "Time info: 213m 58s (- 10484m 49s)\n",
      "Train Epoch: 2 [10000/199564 (5%)]\tLoss: 2.317470\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hidden_size = 256\n",
    "train_loader, test_loader = data_loader(pairs)\n",
    "\n",
    "encoder = EncoderRNN(input_elem.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, output_elem.n_words).to(device)\n",
    "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "train_losses = trainIters(encoder, decoder, train_loader, EPOCH=100, print_every=10000, model_folder='AERNN_zinc_hidden_256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 10s (- 128m 11s) (100 0%) 3.5220\n",
      "0m 20s (- 128m 22s) (200 0%) 2.3364\n",
      "0m 27s (- 115m 17s) (300 0%) 2.0428\n",
      "0m 34s (- 106m 22s) (400 0%) 1.8116\n",
      "0m 43s (- 107m 56s) (500 0%) 1.8604\n",
      "0m 51s (- 106m 2s) (600 0%) 1.6656\n",
      "1m 1s (- 109m 7s) (700 0%) 1.7139\n",
      "1m 10s (- 109m 39s) (800 1%) 1.6917\n",
      "1m 17s (- 106m 56s) (900 1%) 1.6038\n",
      "1m 24s (- 104m 48s) (1000 1%) 1.6853\n",
      "1m 31s (- 102m 50s) (1100 1%) 1.5782\n",
      "1m 39s (- 101m 58s) (1200 1%) 1.6039\n",
      "1m 47s (- 101m 27s) (1300 1%) 1.6759\n",
      "1m 54s (- 100m 30s) (1400 1%) 1.6403\n",
      "2m 1s (- 99m 13s) (1500 2%) 1.5226\n",
      "2m 11s (- 100m 51s) (1600 2%) 1.4420\n",
      "2m 20s (- 100m 42s) (1700 2%) 1.6331\n",
      "2m 26s (- 99m 33s) (1800 2%) 1.6021\n",
      "2m 34s (- 98m 48s) (1900 2%) 1.5791\n",
      "2m 40s (- 97m 34s) (2000 2%) 1.4985\n",
      "2m 47s (- 96m 54s) (2100 2%) 1.5189\n",
      "2m 53s (- 95m 45s) (2200 2%) 1.5236\n",
      "2m 57s (- 93m 43s) (2300 3%) 1.4737\n",
      "3m 4s (- 92m 49s) (2400 3%) 1.5091\n",
      "3m 9s (- 91m 49s) (2500 3%) 1.5090\n",
      "3m 14s (- 90m 3s) (2600 3%) 1.4155\n",
      "3m 20s (- 89m 28s) (2700 3%) 1.4947\n",
      "3m 26s (- 88m 41s) (2800 3%) 1.3517\n",
      "3m 31s (- 87m 30s) (2900 3%) 1.3591\n",
      "3m 38s (- 87m 23s) (3000 4%) 1.5045\n",
      "3m 44s (- 86m 56s) (3100 4%) 1.3390\n",
      "3m 51s (- 86m 32s) (3200 4%) 1.4238\n",
      "3m 57s (- 86m 4s) (3300 4%) 1.3509\n",
      "4m 3s (- 85m 24s) (3400 4%) 1.1968\n",
      "4m 9s (- 84m 54s) (3500 4%) 1.3724\n",
      "4m 16s (- 84m 45s) (3600 4%) 1.3693\n",
      "4m 22s (- 84m 23s) (3700 4%) 1.4392\n",
      "4m 29s (- 84m 14s) (3800 5%) 1.3771\n",
      "4m 35s (- 83m 47s) (3900 5%) 1.4305\n",
      "4m 42s (- 83m 36s) (4000 5%) 1.4611\n",
      "4m 48s (- 83m 13s) (4100 5%) 1.2602\n",
      "4m 54s (- 82m 51s) (4200 5%) 1.4025\n",
      "5m 1s (- 82m 43s) (4300 5%) 1.3883\n",
      "5m 8s (- 82m 36s) (4400 5%) 1.3302\n",
      "5m 14s (- 82m 13s) (4500 6%) 1.3117\n",
      "5m 20s (- 81m 48s) (4600 6%) 1.2944\n",
      "5m 27s (- 81m 42s) (4700 6%) 1.3408\n",
      "5m 32s (- 80m 58s) (4800 6%) 1.4594\n",
      "5m 35s (- 80m 5s) (4900 6%) 1.3967\n",
      "5m 39s (- 79m 10s) (5000 6%) 1.1823\n",
      "5m 46s (- 79m 5s) (5100 6%) 1.2475\n",
      "5m 52s (- 78m 47s) (5200 6%) 1.3721\n",
      "5m 58s (- 78m 32s) (5300 7%) 1.3441\n",
      "6m 4s (- 78m 18s) (5400 7%) 1.2885\n",
      "6m 10s (- 77m 57s) (5500 7%) 1.1521\n",
      "6m 16s (- 77m 46s) (5600 7%) 1.3259\n",
      "6m 22s (- 77m 35s) (5700 7%) 1.2828\n",
      "6m 29s (- 77m 22s) (5800 7%) 1.3408\n",
      "6m 34s (- 77m 3s) (5900 7%) 1.3257\n",
      "6m 40s (- 76m 43s) (6000 8%) 1.2333\n",
      "6m 44s (- 76m 10s) (6100 8%) 1.2398\n",
      "6m 48s (- 75m 38s) (6200 8%) 1.2653\n",
      "6m 55s (- 75m 26s) (6300 8%) 1.2453\n",
      "7m 1s (- 75m 18s) (6400 8%) 1.2638\n",
      "7m 7s (- 75m 5s) (6500 8%) 1.2439\n",
      "7m 13s (- 74m 56s) (6600 8%) 1.2976\n",
      "7m 20s (- 74m 48s) (6700 8%) 1.2821\n",
      "7m 26s (- 74m 37s) (6800 9%) 1.3312\n",
      "7m 32s (- 74m 28s) (6900 9%) 1.2546\n",
      "7m 39s (- 74m 19s) (7000 9%) 1.4265\n",
      "7m 45s (- 74m 15s) (7100 9%) 1.1823\n",
      "7m 50s (- 73m 54s) (7200 9%) 1.2514\n",
      "7m 54s (- 73m 23s) (7300 9%) 1.1481\n",
      "8m 0s (- 73m 12s) (7400 9%) 1.2691\n",
      "8m 7s (- 73m 5s) (7500 10%) 1.3301\n",
      "8m 13s (- 73m 0s) (7600 10%) 1.3863\n",
      "8m 19s (- 72m 46s) (7700 10%) 1.1596\n",
      "8m 23s (- 72m 22s) (7800 10%) 1.2237\n",
      "8m 27s (- 71m 54s) (7900 10%) 1.1930\n",
      "8m 31s (- 71m 26s) (8000 10%) 1.1208\n",
      "8m 35s (- 70m 59s) (8100 10%) 1.1280\n",
      "8m 41s (- 70m 48s) (8200 10%) 1.1682\n",
      "8m 48s (- 70m 44s) (8300 11%) 1.1710\n",
      "8m 52s (- 70m 24s) (8400 11%) 1.2289\n",
      "8m 58s (- 70m 16s) (8500 11%) 1.2103\n",
      "9m 4s (- 70m 5s) (8600 11%) 1.1187\n",
      "9m 10s (- 69m 56s) (8700 11%) 1.2273\n",
      "9m 14s (- 69m 32s) (8800 11%) 1.2376\n",
      "9m 19s (- 69m 14s) (8900 11%) 1.3681\n",
      "9m 25s (- 69m 8s) (9000 12%) 1.0966\n",
      "9m 30s (- 68m 48s) (9100 12%) 1.2970\n",
      "9m 34s (- 68m 27s) (9200 12%) 1.2207\n",
      "9m 38s (- 68m 5s) (9300 12%) 1.0552\n",
      "9m 41s (- 67m 41s) (9400 12%) 1.1859\n",
      "9m 45s (- 67m 20s) (9500 12%) 1.2256\n",
      "9m 50s (- 67m 0s) (9600 12%) 1.2243\n",
      "9m 53s (- 66m 38s) (9700 12%) 1.1651\n",
      "9m 58s (- 66m 19s) (9800 13%) 1.1818\n",
      "10m 2s (- 66m 0s) (9900 13%) 1.1133\n",
      "10m 6s (- 65m 43s) (10000 13%) 1.2352\n",
      "10m 12s (- 65m 35s) (10100 13%) 1.0002\n",
      "10m 19s (- 65m 32s) (10200 13%) 1.1362\n",
      "10m 25s (- 65m 27s) (10300 13%) 1.2246\n",
      "10m 30s (- 65m 15s) (10400 13%) 1.0561\n",
      "10m 36s (- 65m 11s) (10500 14%) 1.2180\n",
      "10m 43s (- 65m 8s) (10600 14%) 1.0571\n",
      "10m 49s (- 65m 3s) (10700 14%) 1.1094\n",
      "10m 55s (- 64m 58s) (10800 14%) 1.0050\n",
      "11m 1s (- 64m 51s) (10900 14%) 1.1265\n",
      "11m 7s (- 64m 43s) (11000 14%) 1.0801\n",
      "11m 14s (- 64m 42s) (11100 14%) 1.2139\n",
      "11m 21s (- 64m 43s) (11200 14%) 1.1503\n",
      "11m 27s (- 64m 38s) (11300 15%) 1.1156\n",
      "11m 34s (- 64m 34s) (11400 15%) 1.1047\n",
      "11m 40s (- 64m 26s) (11500 15%) 1.0116\n",
      "11m 46s (- 64m 19s) (11600 15%) 1.0034\n",
      "11m 52s (- 64m 12s) (11700 15%) 1.0221\n",
      "11m 58s (- 64m 6s) (11800 15%) 0.9560\n",
      "12m 5s (- 64m 7s) (11900 15%) 1.1703\n",
      "12m 12s (- 64m 5s) (12000 16%) 1.2233\n",
      "12m 16s (- 63m 46s) (12100 16%) 1.0484\n",
      "12m 20s (- 63m 31s) (12200 16%) 1.1024\n",
      "12m 24s (- 63m 13s) (12300 16%) 1.1147\n",
      "12m 28s (- 62m 58s) (12400 16%) 1.0752\n",
      "12m 34s (- 62m 50s) (12500 16%) 1.0851\n",
      "12m 40s (- 62m 45s) (12600 16%) 1.0272\n",
      "12m 46s (- 62m 39s) (12700 16%) 0.9360\n",
      "12m 51s (- 62m 26s) (12800 17%) 1.0940\n",
      "12m 55s (- 62m 11s) (12900 17%) 1.0477\n",
      "12m 58s (- 61m 54s) (13000 17%) 0.9909\n",
      "13m 2s (- 61m 39s) (13100 17%) 0.9424\n",
      "13m 6s (- 61m 22s) (13200 17%) 1.0697\n",
      "13m 10s (- 61m 7s) (13300 17%) 1.0464\n",
      "13m 14s (- 60m 52s) (13400 17%) 1.1081\n",
      "13m 21s (- 60m 50s) (13500 18%) 1.0640\n",
      "13m 27s (- 60m 45s) (13600 18%) 0.9047\n",
      "13m 33s (- 60m 38s) (13700 18%) 0.9157\n",
      "13m 38s (- 60m 30s) (13800 18%) 0.9772\n",
      "13m 45s (- 60m 27s) (13900 18%) 1.0685\n",
      "13m 51s (- 60m 24s) (14000 18%) 0.9382\n",
      "13m 58s (- 60m 19s) (14100 18%) 0.8841\n",
      "14m 4s (- 60m 17s) (14200 18%) 0.9664\n",
      "14m 11s (- 60m 13s) (14300 19%) 1.1296\n",
      "14m 17s (- 60m 7s) (14400 19%) 1.0352\n",
      "14m 23s (- 60m 2s) (14500 19%) 1.0227\n",
      "14m 29s (- 59m 58s) (14600 19%) 0.9872\n",
      "14m 35s (- 59m 53s) (14700 19%) 1.0455\n",
      "14m 40s (- 59m 42s) (14800 19%) 1.1062\n",
      "14m 45s (- 59m 29s) (14900 19%) 1.0011\n",
      "14m 49s (- 59m 16s) (15000 20%) 1.0497\n",
      "14m 55s (- 59m 11s) (15100 20%) 0.9456\n",
      "15m 1s (- 59m 7s) (15200 20%) 1.0446\n",
      "15m 8s (- 59m 6s) (15300 20%) 0.9555\n",
      "15m 15s (- 59m 1s) (15400 20%) 1.0022\n",
      "15m 21s (- 58m 56s) (15500 20%) 1.0688\n",
      "15m 26s (- 58m 49s) (15600 20%) 0.8202\n",
      "15m 32s (- 58m 42s) (15700 20%) 1.0404\n",
      "15m 38s (- 58m 36s) (15800 21%) 0.9182\n",
      "15m 42s (- 58m 24s) (15900 21%) 1.0144\n",
      "15m 47s (- 58m 12s) (16000 21%) 1.0001\n",
      "15m 53s (- 58m 7s) (16100 21%) 1.0265\n",
      "15m 59s (- 58m 2s) (16200 21%) 0.9523\n",
      "16m 3s (- 57m 48s) (16300 21%) 0.9021\n",
      "16m 7s (- 57m 36s) (16400 21%) 0.9881\n",
      "16m 12s (- 57m 26s) (16500 22%) 1.0626\n",
      "16m 19s (- 57m 25s) (16600 22%) 0.9117\n",
      "16m 25s (- 57m 21s) (16700 22%) 1.0521\n",
      "16m 31s (- 57m 16s) (16800 22%) 0.9238\n",
      "16m 38s (- 57m 12s) (16900 22%) 0.9546\n",
      "16m 44s (- 57m 7s) (17000 22%) 0.9203\n",
      "16m 50s (- 57m 2s) (17100 22%) 1.0647\n",
      "16m 56s (- 56m 56s) (17200 22%) 0.9782\n",
      "17m 2s (- 56m 50s) (17300 23%) 0.9886\n",
      "17m 9s (- 56m 48s) (17400 23%) 0.9254\n",
      "17m 15s (- 56m 43s) (17500 23%) 0.8641\n",
      "17m 21s (- 56m 37s) (17600 23%) 0.7575\n",
      "17m 27s (- 56m 32s) (17700 23%) 0.9380\n",
      "17m 34s (- 56m 27s) (17800 23%) 0.8983\n",
      "17m 39s (- 56m 21s) (17900 23%) 0.8391\n",
      "17m 46s (- 56m 17s) (18000 24%) 0.9091\n",
      "17m 52s (- 56m 11s) (18100 24%) 0.9194\n",
      "17m 56s (- 56m 0s) (18200 24%) 0.9165\n",
      "18m 0s (- 55m 48s) (18300 24%) 0.7918\n",
      "18m 6s (- 55m 41s) (18400 24%) 0.7527\n",
      "18m 12s (- 55m 36s) (18500 24%) 0.9269\n",
      "18m 18s (- 55m 30s) (18600 24%) 0.9336\n",
      "18m 24s (- 55m 25s) (18700 24%) 0.8756\n",
      "18m 31s (- 55m 21s) (18800 25%) 1.0284\n",
      "18m 37s (- 55m 15s) (18900 25%) 0.9320\n",
      "18m 43s (- 55m 12s) (19000 25%) 0.9720\n",
      "18m 50s (- 55m 7s) (19100 25%) 1.0169\n",
      "18m 56s (- 55m 4s) (19200 25%) 1.0166\n",
      "19m 3s (- 54m 59s) (19300 25%) 0.9375\n",
      "19m 7s (- 54m 49s) (19400 25%) 0.8758\n",
      "19m 11s (- 54m 38s) (19500 26%) 0.8761\n",
      "19m 18s (- 54m 34s) (19600 26%) 0.8731\n",
      "19m 24s (- 54m 28s) (19700 26%) 0.8315\n",
      "19m 30s (- 54m 22s) (19800 26%) 0.8695\n",
      "19m 36s (- 54m 17s) (19900 26%) 0.9761\n",
      "19m 43s (- 54m 15s) (20000 26%) 0.9617\n",
      "19m 50s (- 54m 10s) (20100 26%) 0.8234\n",
      "19m 56s (- 54m 4s) (20200 26%) 0.8771\n",
      "20m 2s (- 54m 0s) (20300 27%) 0.9510\n",
      "20m 8s (- 53m 54s) (20400 27%) 0.9092\n",
      "20m 14s (- 53m 49s) (20500 27%) 0.8358\n",
      "20m 21s (- 53m 45s) (20600 27%) 1.0472\n",
      "20m 27s (- 53m 39s) (20700 27%) 0.8424\n",
      "20m 33s (- 53m 35s) (20800 27%) 0.9922\n",
      "20m 40s (- 53m 29s) (20900 27%) 0.8553\n",
      "20m 46s (- 53m 25s) (21000 28%) 0.8299\n",
      "20m 53s (- 53m 21s) (21100 28%) 0.9601\n",
      "20m 59s (- 53m 17s) (21200 28%) 0.6928\n",
      "21m 6s (- 53m 13s) (21300 28%) 0.9066\n",
      "21m 13s (- 53m 8s) (21400 28%) 0.8284\n",
      "21m 19s (- 53m 2s) (21500 28%) 0.8107\n",
      "21m 25s (- 52m 57s) (21600 28%) 0.8095\n",
      "21m 31s (- 52m 51s) (21700 28%) 0.9092\n",
      "21m 37s (- 52m 46s) (21800 29%) 0.8103\n",
      "21m 43s (- 52m 41s) (21900 29%) 0.8931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21m 50s (- 52m 36s) (22000 29%) 0.9278\n",
      "21m 56s (- 52m 30s) (22100 29%) 0.7945\n",
      "22m 2s (- 52m 24s) (22200 29%) 0.8395\n",
      "22m 8s (- 52m 18s) (22300 29%) 0.7397\n",
      "22m 13s (- 52m 12s) (22400 29%) 0.6711\n",
      "22m 20s (- 52m 7s) (22500 30%) 0.9823\n",
      "22m 26s (- 52m 1s) (22600 30%) 0.9961\n",
      "22m 33s (- 51m 58s) (22700 30%) 0.9354\n",
      "22m 39s (- 51m 52s) (22800 30%) 0.8334\n",
      "22m 45s (- 51m 46s) (22900 30%) 0.8007\n",
      "22m 51s (- 51m 40s) (23000 30%) 0.8409\n",
      "22m 56s (- 51m 33s) (23100 30%) 0.6540\n",
      "23m 2s (- 51m 27s) (23200 30%) 0.7147\n",
      "23m 9s (- 51m 24s) (23300 31%) 0.7961\n",
      "23m 16s (- 51m 19s) (23400 31%) 0.9455\n",
      "23m 22s (- 51m 14s) (23500 31%) 0.7810\n",
      "23m 28s (- 51m 8s) (23600 31%) 0.8589\n",
      "23m 34s (- 51m 2s) (23700 31%) 0.8419\n",
      "23m 41s (- 50m 57s) (23800 31%) 0.8975\n",
      "23m 47s (- 50m 52s) (23900 31%) 0.9432\n",
      "23m 52s (- 50m 44s) (24000 32%) 0.9756\n",
      "23m 56s (- 50m 34s) (24100 32%) 0.8275\n",
      "24m 1s (- 50m 25s) (24200 32%) 0.7859\n",
      "24m 5s (- 50m 15s) (24300 32%) 0.7559\n",
      "24m 9s (- 50m 4s) (24400 32%) 0.8728\n",
      "24m 13s (- 49m 55s) (24500 32%) 0.8970\n",
      "24m 19s (- 49m 49s) (24600 32%) 0.7404\n",
      "24m 25s (- 49m 45s) (24700 32%) 0.9354\n",
      "24m 31s (- 49m 38s) (24800 33%) 0.7369\n",
      "24m 36s (- 49m 31s) (24900 33%) 0.7176\n",
      "24m 43s (- 49m 26s) (25000 33%) 0.8713\n",
      "24m 49s (- 49m 20s) (25100 33%) 0.7597\n",
      "24m 53s (- 49m 11s) (25200 33%) 0.6920\n",
      "24m 57s (- 49m 2s) (25300 33%) 0.9261\n",
      "25m 1s (- 48m 51s) (25400 33%) 0.7717\n",
      "25m 5s (- 48m 41s) (25500 34%) 0.7947\n",
      "25m 10s (- 48m 35s) (25600 34%) 0.7387\n",
      "25m 15s (- 48m 26s) (25700 34%) 0.8470\n",
      "25m 18s (- 48m 16s) (25800 34%) 0.7213\n",
      "25m 24s (- 48m 10s) (25900 34%) 0.7840\n",
      "25m 31s (- 48m 5s) (26000 34%) 0.6897\n",
      "25m 37s (- 47m 59s) (26100 34%) 0.8227\n",
      "25m 42s (- 47m 52s) (26200 34%) 0.8427\n",
      "25m 46s (- 47m 43s) (26300 35%) 0.8818\n",
      "25m 50s (- 47m 33s) (26400 35%) 0.8366\n",
      "25m 53s (- 47m 23s) (26500 35%) 0.6874\n",
      "25m 57s (- 47m 14s) (26600 35%) 0.7376\n",
      "26m 5s (- 47m 11s) (26700 35%) 0.8525\n",
      "26m 12s (- 47m 7s) (26800 35%) 0.9507\n",
      "26m 18s (- 47m 1s) (26900 35%) 0.8494\n",
      "26m 24s (- 46m 56s) (27000 36%) 0.8524\n",
      "26m 30s (- 46m 51s) (27100 36%) 0.8293\n",
      "26m 36s (- 46m 46s) (27200 36%) 0.7191\n",
      "26m 42s (- 46m 40s) (27300 36%) 0.7175\n",
      "26m 46s (- 46m 31s) (27400 36%) 0.9118\n",
      "26m 50s (- 46m 22s) (27500 36%) 0.6674\n",
      "26m 57s (- 46m 18s) (27600 36%) 0.8743\n",
      "27m 4s (- 46m 13s) (27700 36%) 0.7718\n",
      "27m 8s (- 46m 5s) (27800 37%) 0.6627\n",
      "27m 15s (- 46m 0s) (27900 37%) 0.7634\n",
      "27m 21s (- 45m 55s) (28000 37%) 0.7218\n",
      "27m 27s (- 45m 49s) (28100 37%) 0.7044\n",
      "27m 33s (- 45m 44s) (28200 37%) 0.6555\n",
      "27m 39s (- 45m 39s) (28300 37%) 0.7026\n",
      "27m 46s (- 45m 33s) (28400 37%) 0.7482\n",
      "27m 52s (- 45m 29s) (28500 38%) 0.7784\n",
      "27m 59s (- 45m 24s) (28600 38%) 0.7588\n",
      "28m 4s (- 45m 17s) (28700 38%) 0.7841\n",
      "28m 10s (- 45m 12s) (28800 38%) 0.7493\n",
      "28m 15s (- 45m 4s) (28900 38%) 0.6906\n",
      "28m 20s (- 44m 57s) (29000 38%) 0.8105\n",
      "28m 27s (- 44m 53s) (29100 38%) 0.7150\n",
      "28m 33s (- 44m 47s) (29200 38%) 0.7219\n",
      "28m 39s (- 44m 41s) (29300 39%) 0.7117\n",
      "28m 45s (- 44m 35s) (29400 39%) 0.6827\n",
      "28m 51s (- 44m 31s) (29500 39%) 0.7520\n",
      "28m 58s (- 44m 26s) (29600 39%) 0.7932\n",
      "29m 5s (- 44m 21s) (29700 39%) 0.7461\n",
      "29m 11s (- 44m 16s) (29800 39%) 0.7802\n",
      "29m 18s (- 44m 11s) (29900 39%) 0.7064\n",
      "29m 24s (- 44m 6s) (30000 40%) 0.6037\n",
      "29m 30s (- 44m 1s) (30100 40%) 0.6853\n",
      "29m 37s (- 43m 57s) (30200 40%) 0.7091\n",
      "29m 43s (- 43m 51s) (30300 40%) 0.5935\n",
      "29m 49s (- 43m 45s) (30400 40%) 0.7174\n",
      "29m 55s (- 43m 40s) (30500 40%) 0.6422\n",
      "30m 1s (- 43m 34s) (30600 40%) 0.6712\n",
      "30m 5s (- 43m 25s) (30700 40%) 0.6298\n",
      "30m 11s (- 43m 19s) (30800 41%) 0.8271\n",
      "30m 18s (- 43m 14s) (30900 41%) 0.7879\n",
      "30m 24s (- 43m 10s) (31000 41%) 0.8539\n",
      "30m 30s (- 43m 4s) (31100 41%) 0.5883\n",
      "30m 36s (- 42m 58s) (31200 41%) 0.7582\n",
      "30m 41s (- 42m 51s) (31300 41%) 0.6925\n",
      "30m 48s (- 42m 46s) (31400 41%) 0.8023\n",
      "30m 54s (- 42m 40s) (31500 42%) 0.6698\n",
      "31m 0s (- 42m 34s) (31600 42%) 0.7930\n",
      "31m 3s (- 42m 25s) (31700 42%) 0.6790\n",
      "31m 7s (- 42m 17s) (31800 42%) 0.6578\n",
      "31m 11s (- 42m 9s) (31900 42%) 0.7310\n",
      "31m 16s (- 42m 0s) (32000 42%) 0.6947\n",
      "31m 20s (- 41m 52s) (32100 42%) 0.6156\n",
      "31m 25s (- 41m 46s) (32200 42%) 0.7611\n",
      "31m 31s (- 41m 40s) (32300 43%) 0.8069\n",
      "31m 38s (- 41m 35s) (32400 43%) 0.7578\n",
      "31m 42s (- 41m 28s) (32500 43%) 0.6625\n",
      "31m 46s (- 41m 20s) (32600 43%) 0.6543\n",
      "31m 51s (- 41m 12s) (32700 43%) 0.6728\n",
      "31m 55s (- 41m 4s) (32800 43%) 0.5979\n",
      "32m 0s (- 40m 57s) (32900 43%) 0.6035\n",
      "32m 6s (- 40m 51s) (33000 44%) 0.6398\n",
      "32m 9s (- 40m 42s) (33100 44%) 0.4964\n",
      "32m 13s (- 40m 34s) (33200 44%) 0.5765\n",
      "32m 18s (- 40m 27s) (33300 44%) 0.7201\n",
      "32m 22s (- 40m 19s) (33400 44%) 0.6452\n",
      "32m 26s (- 40m 11s) (33500 44%) 0.7309\n",
      "32m 31s (- 40m 4s) (33600 44%) 0.7811\n",
      "32m 35s (- 39m 56s) (33700 44%) 0.6830\n",
      "32m 39s (- 39m 48s) (33800 45%) 0.6544\n",
      "32m 44s (- 39m 41s) (33900 45%) 0.5842\n",
      "32m 49s (- 39m 34s) (34000 45%) 0.5808\n",
      "32m 53s (- 39m 26s) (34100 45%) 0.5962\n",
      "32m 57s (- 39m 19s) (34200 45%) 0.7346\n",
      "33m 3s (- 39m 13s) (34300 45%) 0.5971\n",
      "33m 10s (- 39m 8s) (34400 45%) 0.6859\n",
      "33m 16s (- 39m 4s) (34500 46%) 0.7888\n",
      "33m 21s (- 38m 56s) (34600 46%) 0.6673\n",
      "33m 26s (- 38m 50s) (34700 46%) 0.6666\n",
      "33m 33s (- 38m 45s) (34800 46%) 0.6029\n",
      "33m 39s (- 38m 39s) (34900 46%) 0.6112\n",
      "33m 44s (- 38m 34s) (35000 46%) 0.6972\n",
      "33m 51s (- 38m 29s) (35100 46%) 0.6914\n",
      "33m 57s (- 38m 23s) (35200 46%) 0.6838\n",
      "34m 3s (- 38m 18s) (35300 47%) 0.6559\n",
      "34m 10s (- 38m 13s) (35400 47%) 0.7202\n",
      "34m 16s (- 38m 7s) (35500 47%) 0.4920\n",
      "34m 21s (- 38m 1s) (35600 47%) 0.5843\n",
      "34m 28s (- 37m 56s) (35700 47%) 0.5899\n",
      "34m 34s (- 37m 51s) (35800 47%) 0.6308\n",
      "34m 40s (- 37m 46s) (35900 47%) 0.6358\n",
      "34m 47s (- 37m 41s) (36000 48%) 0.7543\n",
      "34m 53s (- 37m 36s) (36100 48%) 0.7420\n",
      "35m 0s (- 37m 30s) (36200 48%) 0.7084\n",
      "35m 7s (- 37m 26s) (36300 48%) 0.6252\n",
      "35m 13s (- 37m 21s) (36400 48%) 0.6992\n",
      "35m 19s (- 37m 16s) (36500 48%) 0.6450\n",
      "35m 26s (- 37m 10s) (36600 48%) 0.7269\n",
      "35m 32s (- 37m 5s) (36700 48%) 0.6749\n",
      "35m 38s (- 36m 59s) (36800 49%) 0.7218\n",
      "35m 45s (- 36m 54s) (36900 49%) 0.6069\n",
      "35m 48s (- 36m 47s) (37000 49%) 0.4748\n",
      "35m 54s (- 36m 41s) (37100 49%) 0.5683\n",
      "36m 0s (- 36m 35s) (37200 49%) 0.6590\n",
      "36m 7s (- 36m 30s) (37300 49%) 0.8264\n",
      "36m 13s (- 36m 25s) (37400 49%) 0.6252\n",
      "36m 20s (- 36m 20s) (37500 50%) 0.6022\n",
      "36m 25s (- 36m 14s) (37600 50%) 0.6464\n",
      "36m 29s (- 36m 6s) (37700 50%) 0.6890\n",
      "36m 35s (- 36m 0s) (37800 50%) 0.5511\n",
      "36m 42s (- 35m 55s) (37900 50%) 0.7772\n",
      "36m 48s (- 35m 50s) (38000 50%) 0.6515\n",
      "36m 52s (- 35m 42s) (38100 50%) 0.6202\n",
      "36m 56s (- 35m 35s) (38200 50%) 0.5809\n",
      "37m 0s (- 35m 27s) (38300 51%) 0.5858\n",
      "37m 6s (- 35m 22s) (38400 51%) 0.6536\n",
      "37m 12s (- 35m 16s) (38500 51%) 0.6451\n",
      "37m 18s (- 35m 10s) (38600 51%) 0.5591\n",
      "37m 25s (- 35m 5s) (38700 51%) 0.6898\n",
      "37m 31s (- 35m 0s) (38800 51%) 0.5978\n",
      "37m 37s (- 34m 55s) (38900 51%) 0.7357\n",
      "37m 43s (- 34m 49s) (39000 52%) 0.6904\n",
      "37m 50s (- 34m 44s) (39100 52%) 0.5983\n",
      "37m 55s (- 34m 38s) (39200 52%) 0.5665\n",
      "38m 2s (- 34m 33s) (39300 52%) 0.5991\n",
      "38m 6s (- 34m 26s) (39400 52%) 0.5677\n",
      "38m 12s (- 34m 20s) (39500 52%) 0.6480\n",
      "38m 19s (- 34m 15s) (39600 52%) 0.7569\n",
      "38m 24s (- 34m 9s) (39700 52%) 0.4789\n",
      "38m 30s (- 34m 3s) (39800 53%) 0.4604\n",
      "38m 36s (- 33m 58s) (39900 53%) 0.6143\n",
      "38m 43s (- 33m 52s) (40000 53%) 0.5800\n",
      "38m 49s (- 33m 47s) (40100 53%) 0.6324\n",
      "38m 56s (- 33m 42s) (40200 53%) 0.5632\n",
      "39m 2s (- 33m 36s) (40300 53%) 0.6072\n",
      "39m 6s (- 33m 29s) (40400 53%) 0.5230\n",
      "39m 11s (- 33m 22s) (40500 54%) 0.6113\n",
      "39m 17s (- 33m 17s) (40600 54%) 0.5230\n",
      "39m 23s (- 33m 11s) (40700 54%) 0.4156\n",
      "39m 28s (- 33m 5s) (40800 54%) 0.4599\n",
      "39m 34s (- 33m 0s) (40900 54%) 0.5729\n",
      "39m 41s (- 32m 54s) (41000 54%) 0.6069\n",
      "39m 47s (- 32m 49s) (41100 54%) 0.4976\n",
      "39m 53s (- 32m 44s) (41200 54%) 0.5667\n",
      "40m 1s (- 32m 39s) (41300 55%) 0.6130\n",
      "40m 7s (- 32m 34s) (41400 55%) 0.3852\n",
      "40m 13s (- 32m 28s) (41500 55%) 0.5094\n",
      "40m 20s (- 32m 23s) (41600 55%) 0.5665\n",
      "40m 27s (- 32m 18s) (41700 55%) 0.7082\n",
      "40m 33s (- 32m 12s) (41800 55%) 0.5881\n",
      "40m 39s (- 32m 7s) (41900 55%) 0.4611\n",
      "40m 45s (- 32m 1s) (42000 56%) 0.6838\n",
      "40m 49s (- 31m 54s) (42100 56%) 0.6143\n",
      "40m 53s (- 31m 46s) (42200 56%) 0.4993\n",
      "40m 57s (- 31m 39s) (42300 56%) 0.5599\n",
      "41m 3s (- 31m 34s) (42400 56%) 0.6391\n",
      "41m 9s (- 31m 28s) (42500 56%) 0.6109\n",
      "41m 15s (- 31m 23s) (42600 56%) 0.6031\n",
      "41m 22s (- 31m 17s) (42700 56%) 0.5674\n",
      "41m 28s (- 31m 12s) (42800 57%) 0.4634\n",
      "41m 34s (- 31m 6s) (42900 57%) 0.5296\n",
      "41m 40s (- 31m 0s) (43000 57%) 0.6424\n",
      "41m 47s (- 30m 55s) (43100 57%) 0.6076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41m 53s (- 30m 49s) (43200 57%) 0.5310\n",
      "41m 59s (- 30m 44s) (43300 57%) 0.6087\n",
      "42m 6s (- 30m 39s) (43400 57%) 0.6422\n",
      "42m 12s (- 30m 33s) (43500 57%) 0.5857\n",
      "42m 18s (- 30m 28s) (43600 58%) 0.4270\n",
      "42m 25s (- 30m 22s) (43700 58%) 0.5881\n",
      "42m 31s (- 30m 17s) (43800 58%) 0.5016\n",
      "42m 37s (- 30m 11s) (43900 58%) 0.5450\n",
      "42m 43s (- 30m 6s) (44000 58%) 0.5006\n",
      "42m 48s (- 29m 59s) (44100 58%) 0.5978\n",
      "42m 51s (- 29m 51s) (44200 58%) 0.6138\n",
      "42m 55s (- 29m 44s) (44300 59%) 0.5424\n",
      "43m 0s (- 29m 38s) (44400 59%) 0.5382\n",
      "43m 4s (- 29m 31s) (44500 59%) 0.6179\n",
      "43m 8s (- 29m 24s) (44600 59%) 0.4931\n",
      "43m 12s (- 29m 17s) (44700 59%) 0.5053\n",
      "43m 16s (- 29m 10s) (44800 59%) 0.5585\n",
      "43m 21s (- 29m 4s) (44900 59%) 0.6396\n",
      "43m 28s (- 28m 58s) (45000 60%) 0.5934\n",
      "43m 35s (- 28m 53s) (45100 60%) 0.4935\n",
      "43m 42s (- 28m 48s) (45200 60%) 0.4960\n",
      "43m 47s (- 28m 42s) (45300 60%) 0.5738\n",
      "43m 54s (- 28m 37s) (45400 60%) 0.5533\n",
      "44m 1s (- 28m 32s) (45500 60%) 0.5243\n",
      "44m 5s (- 28m 25s) (45600 60%) 0.5417\n",
      "44m 9s (- 28m 18s) (45700 60%) 0.5540\n",
      "44m 15s (- 28m 13s) (45800 61%) 0.6112\n",
      "44m 22s (- 28m 7s) (45900 61%) 0.4948\n",
      "44m 29s (- 28m 2s) (46000 61%) 0.3787\n",
      "44m 35s (- 27m 57s) (46100 61%) 0.5197\n",
      "44m 40s (- 27m 51s) (46200 61%) 0.5605\n",
      "44m 47s (- 27m 45s) (46300 61%) 0.4952\n",
      "44m 54s (- 27m 41s) (46400 61%) 0.6805\n",
      "45m 1s (- 27m 35s) (46500 62%) 0.4832\n",
      "45m 7s (- 27m 30s) (46600 62%) 0.6430\n",
      "45m 13s (- 27m 24s) (46700 62%) 0.4748\n",
      "45m 20s (- 27m 19s) (46800 62%) 0.6149\n",
      "45m 27s (- 27m 14s) (46900 62%) 0.6856\n",
      "45m 33s (- 27m 8s) (47000 62%) 0.4800\n",
      "45m 38s (- 27m 2s) (47100 62%) 0.4057\n",
      "45m 43s (- 26m 56s) (47200 62%) 0.5094\n",
      "45m 47s (- 26m 49s) (47300 63%) 0.4119\n",
      "45m 52s (- 26m 42s) (47400 63%) 0.6240\n",
      "45m 58s (- 26m 36s) (47500 63%) 0.5564\n",
      "46m 4s (- 26m 31s) (47600 63%) 0.6033\n",
      "46m 8s (- 26m 24s) (47700 63%) 0.4887\n",
      "46m 12s (- 26m 17s) (47800 63%) 0.5167\n",
      "46m 16s (- 26m 10s) (47900 63%) 0.5236\n",
      "46m 20s (- 26m 4s) (48000 64%) 0.4832\n",
      "46m 24s (- 25m 57s) (48100 64%) 0.3715\n",
      "46m 28s (- 25m 50s) (48200 64%) 0.4896\n",
      "46m 32s (- 25m 43s) (48300 64%) 0.4666\n",
      "46m 37s (- 25m 37s) (48400 64%) 0.6033\n",
      "46m 41s (- 25m 30s) (48500 64%) 0.6429\n",
      "46m 45s (- 25m 23s) (48600 64%) 0.6769\n",
      "46m 51s (- 25m 18s) (48700 64%) 0.6342\n",
      "46m 58s (- 25m 13s) (48800 65%) 0.4831\n",
      "47m 5s (- 25m 7s) (48900 65%) 0.6425\n",
      "47m 10s (- 25m 1s) (49000 65%) 0.5020\n",
      "47m 15s (- 24m 55s) (49100 65%) 0.4665\n",
      "47m 19s (- 24m 49s) (49200 65%) 0.6317\n",
      "47m 23s (- 24m 42s) (49300 65%) 0.5004\n",
      "47m 27s (- 24m 35s) (49400 65%) 0.5343\n",
      "47m 31s (- 24m 28s) (49500 66%) 0.5022\n",
      "47m 34s (- 24m 22s) (49600 66%) 0.4978\n",
      "47m 39s (- 24m 15s) (49700 66%) 0.5010\n",
      "47m 46s (- 24m 10s) (49800 66%) 0.4964\n",
      "47m 53s (- 24m 5s) (49900 66%) 0.5468\n",
      "47m 59s (- 23m 59s) (50000 66%) 0.3037\n",
      "48m 4s (- 23m 53s) (50100 66%) 0.4895\n",
      "48m 11s (- 23m 48s) (50200 66%) 0.4614\n",
      "48m 16s (- 23m 42s) (50300 67%) 0.5001\n",
      "48m 23s (- 23m 37s) (50400 67%) 0.4842\n",
      "48m 29s (- 23m 31s) (50500 67%) 0.4370\n",
      "48m 35s (- 23m 25s) (50600 67%) 0.5570\n",
      "48m 41s (- 23m 20s) (50700 67%) 0.5025\n",
      "48m 48s (- 23m 15s) (50800 67%) 0.6028\n",
      "48m 54s (- 23m 9s) (50900 67%) 0.5217\n",
      "49m 0s (- 23m 3s) (51000 68%) 0.5969\n",
      "49m 7s (- 22m 58s) (51100 68%) 0.5473\n",
      "49m 14s (- 22m 53s) (51200 68%) 0.4958\n",
      "49m 21s (- 22m 47s) (51300 68%) 0.5641\n",
      "49m 27s (- 22m 42s) (51400 68%) 0.5407\n",
      "49m 34s (- 22m 37s) (51500 68%) 0.4964\n",
      "49m 41s (- 22m 31s) (51600 68%) 0.5303\n",
      "49m 47s (- 22m 26s) (51700 68%) 0.4852\n",
      "49m 52s (- 22m 20s) (51800 69%) 0.4055\n",
      "49m 59s (- 22m 14s) (51900 69%) 0.5319\n",
      "50m 5s (- 22m 9s) (52000 69%) 0.5324\n",
      "50m 10s (- 22m 3s) (52100 69%) 0.3913\n",
      "50m 16s (- 21m 57s) (52200 69%) 0.4227\n",
      "50m 22s (- 21m 51s) (52300 69%) 0.5444\n",
      "50m 27s (- 21m 45s) (52400 69%) 0.4407\n",
      "50m 33s (- 21m 40s) (52500 70%) 0.5518\n",
      "50m 40s (- 21m 34s) (52600 70%) 0.5291\n",
      "50m 46s (- 21m 29s) (52700 70%) 0.5146\n",
      "50m 53s (- 21m 24s) (52800 70%) 0.5809\n",
      "50m 59s (- 21m 18s) (52900 70%) 0.5843\n",
      "51m 7s (- 21m 13s) (53000 70%) 0.5360\n",
      "51m 14s (- 21m 7s) (53100 70%) 0.5639\n",
      "51m 20s (- 21m 2s) (53200 70%) 0.5145\n",
      "51m 27s (- 20m 56s) (53300 71%) 0.6953\n",
      "51m 33s (- 20m 51s) (53400 71%) 0.4326\n",
      "51m 39s (- 20m 45s) (53500 71%) 0.4457\n",
      "51m 45s (- 20m 39s) (53600 71%) 0.5060\n",
      "51m 50s (- 20m 33s) (53700 71%) 0.4218\n",
      "51m 55s (- 20m 27s) (53800 71%) 0.4634\n",
      "52m 2s (- 20m 22s) (53900 71%) 0.5333\n",
      "52m 9s (- 20m 16s) (54000 72%) 0.5850\n",
      "52m 16s (- 20m 11s) (54100 72%) 0.5771\n",
      "52m 23s (- 20m 6s) (54200 72%) 0.5004\n",
      "52m 28s (- 20m 0s) (54300 72%) 0.5604\n",
      "52m 35s (- 19m 54s) (54400 72%) 0.4561\n",
      "52m 41s (- 19m 49s) (54500 72%) 0.4486\n",
      "52m 45s (- 19m 42s) (54600 72%) 0.4622\n",
      "52m 49s (- 19m 36s) (54700 72%) 0.4308\n",
      "52m 53s (- 19m 29s) (54800 73%) 0.3821\n",
      "52m 59s (- 19m 24s) (54900 73%) 0.4174\n",
      "53m 5s (- 19m 18s) (55000 73%) 0.3643\n",
      "53m 11s (- 19m 12s) (55100 73%) 0.5498\n",
      "53m 17s (- 19m 7s) (55200 73%) 0.5965\n",
      "53m 25s (- 19m 1s) (55300 73%) 0.5148\n",
      "53m 30s (- 18m 56s) (55400 73%) 0.4750\n",
      "53m 36s (- 18m 50s) (55500 74%) 0.4452\n",
      "53m 43s (- 18m 44s) (55600 74%) 0.5420\n",
      "53m 50s (- 18m 39s) (55700 74%) 0.5545\n",
      "53m 56s (- 18m 33s) (55800 74%) 0.5246\n",
      "54m 3s (- 18m 28s) (55900 74%) 0.6115\n",
      "54m 9s (- 18m 22s) (56000 74%) 0.3682\n",
      "54m 15s (- 18m 16s) (56100 74%) 0.3950\n",
      "54m 21s (- 18m 11s) (56200 74%) 0.3475\n",
      "54m 28s (- 18m 5s) (56300 75%) 0.5388\n",
      "54m 34s (- 17m 59s) (56400 75%) 0.4666\n",
      "54m 40s (- 17m 54s) (56500 75%) 0.3781\n",
      "54m 47s (- 17m 48s) (56600 75%) 0.4055\n",
      "54m 53s (- 17m 43s) (56700 75%) 0.5131\n",
      "54m 59s (- 17m 37s) (56800 75%) 0.4001\n",
      "55m 6s (- 17m 31s) (56900 75%) 0.3276\n",
      "55m 12s (- 17m 26s) (57000 76%) 0.4636\n",
      "55m 18s (- 17m 20s) (57100 76%) 0.3968\n",
      "55m 25s (- 17m 14s) (57200 76%) 0.5029\n",
      "55m 30s (- 17m 8s) (57300 76%) 0.3862\n",
      "55m 36s (- 17m 3s) (57400 76%) 0.3945\n",
      "55m 41s (- 16m 57s) (57500 76%) 0.3492\n",
      "55m 47s (- 16m 51s) (57600 76%) 0.4898\n",
      "55m 54s (- 16m 45s) (57700 76%) 0.3919\n",
      "56m 0s (- 16m 40s) (57800 77%) 0.5277\n",
      "56m 6s (- 16m 34s) (57900 77%) 0.4327\n",
      "56m 13s (- 16m 28s) (58000 77%) 0.4403\n",
      "56m 20s (- 16m 23s) (58100 77%) 0.4323\n",
      "56m 26s (- 16m 17s) (58200 77%) 0.3914\n",
      "56m 32s (- 16m 11s) (58300 77%) 0.3790\n",
      "56m 40s (- 16m 6s) (58400 77%) 0.5333\n",
      "56m 46s (- 16m 0s) (58500 78%) 0.4421\n",
      "56m 52s (- 15m 54s) (58600 78%) 0.3901\n",
      "56m 59s (- 15m 49s) (58700 78%) 0.5406\n",
      "57m 5s (- 15m 43s) (58800 78%) 0.4191\n",
      "57m 11s (- 15m 37s) (58900 78%) 0.4389\n",
      "57m 17s (- 15m 32s) (59000 78%) 0.2716\n",
      "57m 23s (- 15m 26s) (59100 78%) 0.4237\n",
      "57m 29s (- 15m 20s) (59200 78%) 0.4277\n",
      "57m 36s (- 15m 15s) (59300 79%) 0.3951\n",
      "57m 43s (- 15m 9s) (59400 79%) 0.4037\n",
      "57m 49s (- 15m 3s) (59500 79%) 0.3852\n",
      "57m 55s (- 14m 58s) (59600 79%) 0.4506\n",
      "58m 1s (- 14m 52s) (59700 79%) 0.4143\n",
      "58m 5s (- 14m 46s) (59800 79%) 0.2911\n",
      "58m 12s (- 14m 40s) (59900 79%) 0.4165\n",
      "58m 18s (- 14m 34s) (60000 80%) 0.3897\n",
      "58m 25s (- 14m 29s) (60100 80%) 0.5049\n",
      "58m 31s (- 14m 23s) (60200 80%) 0.5078\n",
      "58m 36s (- 14m 17s) (60300 80%) 0.3020\n",
      "58m 43s (- 14m 11s) (60400 80%) 0.4773\n",
      "58m 50s (- 14m 6s) (60500 80%) 0.5232\n",
      "58m 56s (- 14m 0s) (60600 80%) 0.3550\n",
      "59m 3s (- 13m 54s) (60700 80%) 0.4295\n",
      "59m 9s (- 13m 48s) (60800 81%) 0.3919\n",
      "59m 15s (- 13m 43s) (60900 81%) 0.4470\n",
      "59m 21s (- 13m 37s) (61000 81%) 0.3494\n",
      "59m 27s (- 13m 31s) (61100 81%) 0.4527\n",
      "59m 34s (- 13m 25s) (61200 81%) 0.4346\n",
      "59m 38s (- 13m 19s) (61300 81%) 0.4694\n",
      "59m 44s (- 13m 13s) (61400 81%) 0.3806\n",
      "59m 50s (- 13m 8s) (61500 82%) 0.5353\n",
      "59m 56s (- 13m 2s) (61600 82%) 0.3796\n",
      "60m 2s (- 12m 56s) (61700 82%) 0.3282\n",
      "60m 9s (- 12m 50s) (61800 82%) 0.4612\n",
      "60m 15s (- 12m 45s) (61900 82%) 0.3976\n",
      "60m 22s (- 12m 39s) (62000 82%) 0.4516\n",
      "60m 28s (- 12m 33s) (62100 82%) 0.3975\n",
      "60m 34s (- 12m 27s) (62200 82%) 0.4777\n",
      "60m 40s (- 12m 22s) (62300 83%) 0.3504\n",
      "60m 47s (- 12m 16s) (62400 83%) 0.4686\n",
      "60m 53s (- 12m 10s) (62500 83%) 0.3179\n",
      "60m 59s (- 12m 4s) (62600 83%) 0.4244\n",
      "61m 6s (- 11m 59s) (62700 83%) 0.4944\n",
      "61m 12s (- 11m 53s) (62800 83%) 0.4081\n",
      "61m 20s (- 11m 47s) (62900 83%) 0.4648\n",
      "61m 26s (- 11m 42s) (63000 84%) 0.3675\n",
      "61m 32s (- 11m 36s) (63100 84%) 0.4706\n",
      "61m 39s (- 11m 30s) (63200 84%) 0.5453\n",
      "61m 44s (- 11m 24s) (63300 84%) 0.4887\n",
      "61m 50s (- 11m 18s) (63400 84%) 0.3488\n",
      "61m 55s (- 11m 12s) (63500 84%) 0.3963\n",
      "62m 0s (- 11m 6s) (63600 84%) 0.4045\n",
      "62m 5s (- 11m 0s) (63700 84%) 0.4175\n",
      "62m 11s (- 10m 55s) (63800 85%) 0.5446\n",
      "62m 16s (- 10m 49s) (63900 85%) 0.4784\n",
      "62m 21s (- 10m 43s) (64000 85%) 0.5467\n",
      "62m 28s (- 10m 37s) (64100 85%) 0.5005\n",
      "62m 32s (- 10m 31s) (64200 85%) 0.4027\n",
      "62m 36s (- 10m 25s) (64300 85%) 0.4364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62m 40s (- 10m 18s) (64400 85%) 0.4051\n",
      "62m 46s (- 10m 13s) (64500 86%) 0.4248\n",
      "62m 53s (- 10m 7s) (64600 86%) 0.4892\n",
      "62m 58s (- 10m 1s) (64700 86%) 0.4825\n",
      "63m 5s (- 9m 55s) (64800 86%) 0.3390\n",
      "63m 11s (- 9m 49s) (64900 86%) 0.3755\n",
      "63m 17s (- 9m 44s) (65000 86%) 0.4289\n",
      "63m 23s (- 9m 38s) (65100 86%) 0.3384\n",
      "63m 31s (- 9m 32s) (65200 86%) 0.4437\n",
      "63m 37s (- 9m 27s) (65300 87%) 0.3405\n",
      "63m 43s (- 9m 21s) (65400 87%) 0.3701\n",
      "63m 50s (- 9m 15s) (65500 87%) 0.4516\n",
      "63m 56s (- 9m 9s) (65600 87%) 0.3538\n",
      "63m 59s (- 9m 3s) (65700 87%) 0.2634\n",
      "64m 6s (- 8m 57s) (65800 87%) 0.4020\n",
      "64m 12s (- 8m 51s) (65900 87%) 0.3076\n",
      "64m 18s (- 8m 46s) (66000 88%) 0.5003\n",
      "64m 24s (- 8m 40s) (66100 88%) 0.4803\n",
      "64m 31s (- 8m 34s) (66200 88%) 0.3723\n",
      "64m 37s (- 8m 28s) (66300 88%) 0.4061\n",
      "64m 43s (- 8m 22s) (66400 88%) 0.3288\n",
      "64m 49s (- 8m 17s) (66500 88%) 0.5015\n",
      "64m 55s (- 8m 11s) (66600 88%) 0.3109\n",
      "65m 1s (- 8m 5s) (66700 88%) 0.4069\n",
      "65m 8s (- 7m 59s) (66800 89%) 0.3871\n",
      "65m 14s (- 7m 53s) (66900 89%) 0.3932\n",
      "65m 21s (- 7m 48s) (67000 89%) 0.4949\n",
      "65m 27s (- 7m 42s) (67100 89%) 0.3741\n",
      "65m 33s (- 7m 36s) (67200 89%) 0.3652\n",
      "65m 39s (- 7m 30s) (67300 89%) 0.2588\n",
      "65m 43s (- 7m 24s) (67400 89%) 0.3778\n",
      "65m 47s (- 7m 18s) (67500 90%) 0.3716\n",
      "65m 51s (- 7m 12s) (67600 90%) 0.4024\n",
      "65m 55s (- 7m 6s) (67700 90%) 0.3463\n",
      "66m 0s (- 7m 0s) (67800 90%) 0.3692\n",
      "66m 4s (- 6m 54s) (67900 90%) 0.3096\n",
      "66m 9s (- 6m 48s) (68000 90%) 0.3394\n",
      "66m 15s (- 6m 42s) (68100 90%) 0.4653\n",
      "66m 21s (- 6m 37s) (68200 90%) 0.4047\n",
      "66m 28s (- 6m 31s) (68300 91%) 0.3885\n",
      "66m 34s (- 6m 25s) (68400 91%) 0.4458\n",
      "66m 39s (- 6m 19s) (68500 91%) 0.4475\n",
      "66m 45s (- 6m 13s) (68600 91%) 0.4679\n",
      "66m 51s (- 6m 7s) (68700 91%) 0.3185\n",
      "66m 57s (- 6m 2s) (68800 91%) 0.4122\n",
      "67m 4s (- 5m 56s) (68900 91%) 0.3716\n",
      "67m 11s (- 5m 50s) (69000 92%) 0.3495\n",
      "67m 17s (- 5m 44s) (69100 92%) 0.4218\n",
      "67m 23s (- 5m 38s) (69200 92%) 0.3118\n",
      "67m 29s (- 5m 33s) (69300 92%) 0.3731\n",
      "67m 35s (- 5m 27s) (69400 92%) 0.3729\n",
      "67m 42s (- 5m 21s) (69500 92%) 0.4244\n",
      "67m 49s (- 5m 15s) (69600 92%) 0.3440\n",
      "67m 53s (- 5m 9s) (69700 92%) 0.4347\n",
      "67m 57s (- 5m 3s) (69800 93%) 0.4562\n",
      "68m 3s (- 4m 57s) (69900 93%) 0.3293\n",
      "68m 8s (- 4m 52s) (70000 93%) 0.2866\n",
      "68m 14s (- 4m 46s) (70100 93%) 0.3589\n",
      "68m 20s (- 4m 40s) (70200 93%) 0.3718\n",
      "68m 27s (- 4m 34s) (70300 93%) 0.3877\n",
      "68m 33s (- 4m 28s) (70400 93%) 0.3733\n",
      "68m 40s (- 4m 23s) (70500 94%) 0.3224\n",
      "68m 47s (- 4m 17s) (70600 94%) 0.3908\n",
      "68m 52s (- 4m 11s) (70700 94%) 0.3783\n",
      "68m 58s (- 4m 5s) (70800 94%) 0.3138\n",
      "69m 5s (- 3m 59s) (70900 94%) 0.4942\n",
      "69m 11s (- 3m 53s) (71000 94%) 0.3763\n",
      "69m 18s (- 3m 48s) (71100 94%) 0.4581\n",
      "69m 22s (- 3m 42s) (71200 94%) 0.4156\n",
      "69m 26s (- 3m 36s) (71300 95%) 0.4751\n",
      "69m 30s (- 3m 30s) (71400 95%) 0.4834\n",
      "69m 35s (- 3m 24s) (71500 95%) 0.4192\n",
      "69m 39s (- 3m 18s) (71600 95%) 0.3991\n",
      "69m 45s (- 3m 12s) (71700 95%) 0.3826\n",
      "69m 49s (- 3m 6s) (71800 95%) 0.3444\n",
      "69m 54s (- 3m 0s) (71900 95%) 0.4606\n",
      "69m 59s (- 2m 54s) (72000 96%) 0.4863\n",
      "70m 6s (- 2m 49s) (72100 96%) 0.4221\n",
      "70m 12s (- 2m 43s) (72200 96%) 0.4319\n",
      "70m 18s (- 2m 37s) (72300 96%) 0.3980\n",
      "70m 25s (- 2m 31s) (72400 96%) 0.4570\n",
      "70m 33s (- 2m 25s) (72500 96%) 0.3970\n",
      "70m 39s (- 2m 20s) (72600 96%) 0.4765\n",
      "70m 45s (- 2m 14s) (72700 96%) 0.4129\n",
      "70m 51s (- 2m 8s) (72800 97%) 0.4227\n",
      "70m 57s (- 2m 2s) (72900 97%) 0.4033\n",
      "71m 2s (- 1m 56s) (73000 97%) 0.3720\n",
      "71m 6s (- 1m 50s) (73100 97%) 0.4032\n",
      "71m 11s (- 1m 45s) (73200 97%) 0.3685\n",
      "71m 18s (- 1m 39s) (73300 97%) 0.2523\n",
      "71m 23s (- 1m 33s) (73400 97%) 0.2878\n",
      "71m 28s (- 1m 27s) (73500 98%) 0.3351\n",
      "71m 35s (- 1m 21s) (73600 98%) 0.3251\n",
      "71m 42s (- 1m 15s) (73700 98%) 0.3909\n",
      "71m 48s (- 1m 10s) (73800 98%) 0.5004\n",
      "71m 55s (- 1m 4s) (73900 98%) 0.3886\n",
      "72m 1s (- 0m 58s) (74000 98%) 0.3269\n",
      "72m 6s (- 0m 52s) (74100 98%) 0.3846\n",
      "72m 14s (- 0m 46s) (74200 98%) 0.3258\n",
      "72m 18s (- 0m 40s) (74300 99%) 0.3502\n",
      "72m 24s (- 0m 35s) (74400 99%) 0.4322\n",
      "72m 28s (- 0m 29s) (74500 99%) 0.3751\n",
      "72m 35s (- 0m 23s) (74600 99%) 0.3024\n",
      "72m 41s (- 0m 17s) (74700 99%) 0.4576\n",
      "72m 48s (- 0m 11s) (74800 99%) 0.4316\n",
      "72m 54s (- 0m 5s) (74900 99%) 0.3978\n",
      "73m 0s (- 0m 0s) (75000 100%) 0.3951\n",
      "CPU times: user 5h 2min 46s, sys: 3h 25min 26s, total: 8h 28min 13s\n",
      "Wall time: 1h 13min\n"
     ]
    }
   ],
   "source": [
    "# train_losses = trainIters(encoder, decoder, 75000, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 249455 sentence pairs\n",
      "Trimmed to 249455 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "input_elem 36\n",
      "output_elem 36\n",
      "['Cc1cccc(NC(=O)[C@@H](C)SCCO)c1', 'Cc1cccc(NC(=O)[C@@H](C)SCCO)c1']\n"
     ]
    }
   ],
   "source": [
    "input_elem, output_elem, pairs = prepareSMILES(zinc_df['smiles'].values)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1128 sentence pairs\n",
      "Trimmed to 1128 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "input_elem 33\n",
      "output_elem 33\n",
      "['CC2Nc1cc(Cl)c(cc1C(=O)N2c3ccccc3C)S(N)(=O)=O ', 'CC2Nc1cc(Cl)c(cc1C(=O)N2c3ccccc3C)S(N)(=O)=O ']\n"
     ]
    }
   ],
   "source": [
    "input_elem, output_elem, pairs = prepareSMILES(esol_df['smiles'].values)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 57s (- 145m 10s) (1000 1%) 2.6470\n",
      "3m 51s (- 140m 38s) (2000 2%) 2.1069\n",
      "5m 47s (- 139m 5s) (3000 4%) 2.0356\n",
      "7m 47s (- 138m 26s) (4000 5%) 1.9442\n",
      "9m 22s (- 131m 13s) (5000 6%) 1.9220\n",
      "11m 18s (- 130m 8s) (6000 8%) 1.8527\n",
      "13m 20s (- 129m 38s) (7000 9%) 1.8539\n",
      "15m 16s (- 127m 55s) (8000 10%) 1.8075\n",
      "17m 10s (- 125m 55s) (9000 12%) 1.7437\n",
      "19m 5s (- 124m 7s) (10000 13%) 1.7192\n",
      "20m 57s (- 121m 58s) (11000 14%) 1.7157\n",
      "22m 43s (- 119m 16s) (12000 16%) 1.6665\n",
      "24m 36s (- 117m 21s) (13000 17%) 1.6682\n",
      "26m 29s (- 115m 27s) (14000 18%) 1.6320\n",
      "28m 24s (- 113m 37s) (15000 20%) 1.5999\n",
      "30m 17s (- 111m 41s) (16000 21%) 1.6093\n",
      "31m 54s (- 108m 50s) (17000 22%) 1.5495\n",
      "33m 54s (- 107m 21s) (18000 24%) 1.5103\n",
      "35m 36s (- 104m 56s) (19000 25%) 1.5547\n",
      "37m 18s (- 102m 36s) (20000 26%) 1.5002\n",
      "39m 18s (- 101m 4s) (21000 28%) 1.4769\n",
      "41m 5s (- 99m 0s) (22000 29%) 1.4842\n",
      "42m 49s (- 96m 48s) (23000 30%) 1.4368\n",
      "44m 39s (- 94m 54s) (24000 32%) 1.4193\n",
      "46m 15s (- 92m 30s) (25000 33%) 1.4362\n",
      "48m 18s (- 91m 3s) (26000 34%) 1.4412\n",
      "49m 59s (- 88m 51s) (27000 36%) 1.4226\n",
      "51m 45s (- 86m 52s) (28000 37%) 1.4178\n",
      "53m 43s (- 85m 13s) (29000 38%) 1.3615\n",
      "55m 35s (- 83m 23s) (30000 40%) 1.3906\n",
      "57m 40s (- 81m 52s) (31000 41%) 1.3271\n",
      "59m 30s (- 79m 58s) (32000 42%) 1.3488\n",
      "61m 34s (- 78m 21s) (33000 44%) 1.3551\n",
      "63m 36s (- 76m 41s) (34000 45%) 1.3582\n",
      "65m 30s (- 74m 51s) (35000 46%) 1.3503\n",
      "67m 4s (- 72m 39s) (36000 48%) 1.3580\n",
      "68m 44s (- 70m 35s) (37000 49%) 1.3028\n",
      "70m 35s (- 68m 44s) (38000 50%) 1.3596\n",
      "72m 40s (- 67m 4s) (39000 52%) 1.3025\n",
      "74m 40s (- 65m 20s) (40000 53%) 1.2981\n",
      "76m 17s (- 63m 15s) (41000 54%) 1.3285\n",
      "78m 21s (- 61m 34s) (42000 56%) 1.2685\n",
      "80m 22s (- 59m 48s) (43000 57%) 1.3176\n",
      "82m 9s (- 57m 52s) (44000 58%) 1.2792\n",
      "84m 11s (- 56m 7s) (45000 60%) 1.3311\n",
      "86m 13s (- 54m 21s) (46000 61%) 1.2938\n",
      "88m 4s (- 52m 28s) (47000 62%) 1.2488\n",
      "89m 51s (- 50m 32s) (48000 64%) 1.2911\n",
      "91m 33s (- 48m 34s) (49000 65%) 1.2557\n",
      "92m 55s (- 46m 27s) (50000 66%) 1.2234\n",
      "94m 42s (- 44m 33s) (51000 68%) 1.2776\n",
      "96m 22s (- 42m 37s) (52000 69%) 1.2009\n",
      "97m 55s (- 40m 39s) (53000 70%) 1.2663\n",
      "99m 54s (- 38m 51s) (54000 72%) 1.2406\n",
      "101m 53s (- 37m 2s) (55000 73%) 1.2587\n",
      "103m 47s (- 35m 13s) (56000 74%) 1.2172\n",
      "105m 23s (- 33m 16s) (57000 76%) 1.2482\n",
      "107m 14s (- 31m 25s) (58000 77%) 1.2503\n",
      "109m 3s (- 29m 34s) (59000 78%) 1.2183\n",
      "110m 59s (- 27m 44s) (60000 80%) 1.1950\n",
      "112m 45s (- 25m 52s) (61000 81%) 1.2090\n",
      "114m 46s (- 24m 3s) (62000 82%) 1.2440\n",
      "116m 33s (- 22m 12s) (63000 84%) 1.2630\n",
      "118m 24s (- 20m 21s) (64000 85%) 1.1854\n",
      "120m 20s (- 18m 30s) (65000 86%) 1.2155\n",
      "122m 16s (- 16m 40s) (66000 88%) 1.2427\n",
      "124m 11s (- 14m 49s) (67000 89%) 1.3432\n",
      "126m 3s (- 12m 58s) (68000 90%) 1.2404\n",
      "128m 3s (- 11m 8s) (69000 92%) 1.2183\n",
      "129m 55s (- 9m 16s) (70000 93%) 1.2586\n",
      "131m 21s (- 7m 24s) (71000 94%) 1.2023\n",
      "132m 52s (- 5m 32s) (72000 96%) 1.1905\n",
      "134m 56s (- 3m 41s) (73000 97%) 1.2161\n",
      "136m 38s (- 1m 50s) (74000 98%) 1.1536\n",
      "138m 34s (- 0m 0s) (75000 100%) 1.1567\n",
      "CPU times: user 9h 31min 11s, sys: 6h 35min 37s, total: 16h 6min 48s\n",
      "Wall time: 2h 18min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hidden_size = 256\n",
    "encoder_zinc = EncoderRNN(input_elem.n_words, hidden_size).to(device)\n",
    "decoder_zinc = DecoderRNN(hidden_size, output_elem.n_words).to(device)\n",
    "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "train_losses_zinc = trainIters(encoder_zinc, decoder_zinc, 75000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_losses_zinc)\n",
    "# plt.xlabel('iter')\n",
    "# plt.ylabel('loss')\n",
    "# plt.show()\n",
    "showPlot(train_losses_zinc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statSMILES(encoder, decoder, data_pairs):\n",
    "    smiles_in = np.array(data_pairs)[:, 0]\n",
    "    smiles_real = np.array(data_pairs)[:, 0]\n",
    "    smiles_pred = []\n",
    "    smiles_len_ele = []\n",
    "    smiles_error_rate = []\n",
    "    for index, pair in enumerate(smiles_in):\n",
    "        output_words, _ = evaluate(encoder, decoder, pair)\n",
    "        output_sentence = ''.join(output_words[:-1])\n",
    "        smiles_pred.append(output_sentence)\n",
    "        \n",
    "        smiles_len_ele.append(len(output_sentence))\n",
    "        err_elem = 0\n",
    "\n",
    "        try:\n",
    "            for index_char, char in enumerate(output_sentence):\n",
    "                if char is not smiles_real[index][index_char]:\n",
    "                    err_elem += 1\n",
    "        except:\n",
    "            err_elem += (len(output_sentence) - index_char)\n",
    "\n",
    "        try:\n",
    "            err_rate = err_elem/smiles_len_ele[index]\n",
    "            smiles_error_rate.append(err_rate)\n",
    "        except:\n",
    "            smiles_error_rate.append(None)\n",
    "\n",
    "    chem_AE_dict = {'real SMILES': smiles_real, 'predict SMILES': smiles_pred, \n",
    "                    'ERROR rate': smiles_error_rate, 'len elements': smiles_len_ele}\n",
    "    return chem_AE_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERROR rate</th>\n",
       "      <th>len elements</th>\n",
       "      <th>predict SMILES</th>\n",
       "      <th>real SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.584906</td>\n",
       "      <td>53</td>\n",
       "      <td>OCC3OCC2C(OCCCCC(O)cccccccc1ON(()O)C)C(CO)CO(C...</td>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.136364</td>\n",
       "      <td>22</td>\n",
       "      <td>Cc1occc1C(=O)N2ccccccc</td>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>22</td>\n",
       "      <td>CC(C)=CCCCCC(C)=CC(=O)</td>\n",
       "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>39</td>\n",
       "      <td>c1ccc2c(c1)ccccccccccccccccccccccc4cc34</td>\n",
       "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>c1ccsc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>c2ccc1scnc1c2</td>\n",
       "      <td>c2ccc1scnc1c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>Clc1cc(Cl)c(c(Cl)c1)c2c(Cl)cccc2Cl</td>\n",
       "      <td>Clc1cc(Cl)c(c(Cl)c1)c2c(Cl)cccc2Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>CC12CCC3C(CCc4cc(O)ccc34)C2CCC1O</td>\n",
       "      <td>CC12CCC3C(CCc4cc(O)ccc34)C2CCC1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.403846</td>\n",
       "      <td>52</td>\n",
       "      <td>ClC4=C(Cl)C5(Cl)C3C1CCC2CCCC2CCCCCCC(CCCCCl)(C...</td>\n",
       "      <td>ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>52</td>\n",
       "      <td>COc5ccccCOCCCC1OCCcccccccccccccCcCcO()=cCC(3)C...</td>\n",
       "      <td>COc5cc4OCC3Oc2c1CC(Oc1ccc2C(=O)C3c4cc5OC)C(C)=C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>9</td>\n",
       "      <td>O=C1CCCC1</td>\n",
       "      <td>O=C1CCCN1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>20</td>\n",
       "      <td>Clc1ccc2cccccccccccc</td>\n",
       "      <td>Clc1ccc2ccccc2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>CCCC=C</td>\n",
       "      <td>CCCC=C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>26</td>\n",
       "      <td>CCC1(C(=O)NCN1=O)c2cccccc2</td>\n",
       "      <td>CCC1(C(=O)NCNC1=O)c2ccccc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.575758</td>\n",
       "      <td>33</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC</td>\n",
       "      <td>CCCCCCCCCCCCCC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ERROR rate  len elements  \\\n",
       "0     0.584906            53   \n",
       "1     0.136364            22   \n",
       "2     0.500000            22   \n",
       "3     0.307692            39   \n",
       "4     0.000000             7   \n",
       "5     0.000000            13   \n",
       "6     0.000000            34   \n",
       "7     0.000000            32   \n",
       "8     0.403846            52   \n",
       "9     0.653846            52   \n",
       "10    0.111111             9   \n",
       "11    0.300000            20   \n",
       "12    0.000000             6   \n",
       "13    0.269231            26   \n",
       "14    0.575758            33   \n",
       "\n",
       "                                       predict SMILES  \\\n",
       "0   OCC3OCC2C(OCCCCC(O)cccccccc1ON(()O)C)C(CO)CO(C...   \n",
       "1                              Cc1occc1C(=O)N2ccccccc   \n",
       "2                              CC(C)=CCCCCC(C)=CC(=O)   \n",
       "3             c1ccc2c(c1)ccccccccccccccccccccccc4cc34   \n",
       "4                                             c1ccsc1   \n",
       "5                                       c2ccc1scnc1c2   \n",
       "6                  Clc1cc(Cl)c(c(Cl)c1)c2c(Cl)cccc2Cl   \n",
       "7                    CC12CCC3C(CCc4cc(O)ccc34)C2CCC1O   \n",
       "8   ClC4=C(Cl)C5(Cl)C3C1CCC2CCCC2CCCCCCC(CCCCCl)(C...   \n",
       "9   COc5ccccCOCCCC1OCCcccccccccccccCcCcO()=cCC(3)C...   \n",
       "10                                          O=C1CCCC1   \n",
       "11                               Clc1ccc2cccccccccccc   \n",
       "12                                             CCCC=C   \n",
       "13                         CCC1(C(=O)NCN1=O)c2cccccc2   \n",
       "14                  CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC   \n",
       "\n",
       "                                          real SMILES  \n",
       "0   OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...  \n",
       "1                              Cc1occc1C(=O)Nc2ccccc2  \n",
       "2                                CC(C)=CCCC(C)=CC(=O)  \n",
       "3                  c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43  \n",
       "4                                             c1ccsc1  \n",
       "5                                      c2ccc1scnc1c2   \n",
       "6                  Clc1cc(Cl)c(c(Cl)c1)c2c(Cl)cccc2Cl  \n",
       "7                    CC12CCC3C(CCc4cc(O)ccc34)C2CCC1O  \n",
       "8      ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl  \n",
       "9    COc5cc4OCC3Oc2c1CC(Oc1ccc2C(=O)C3c4cc5OC)C(C)=C   \n",
       "10                                          O=C1CCCN1  \n",
       "11                                   Clc1ccc2ccccc2c1  \n",
       "12                                             CCCC=C  \n",
       "13                         CCC1(C(=O)NCNC1=O)c2ccccc2  \n",
       "14                                     CCCCCCCCCCCCCC  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AERNN_pred_structure_dict_emb = statSMILES(encoder, decoder, pairs[:20])\n",
    "AERNN_pred_structure_train_df = pd.DataFrame(AERNN_pred_structure_dict_emb)\n",
    "AERNN_pred_structure_train_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERROR rate</th>\n",
       "      <th>len elements</th>\n",
       "      <th>predict SMILES</th>\n",
       "      <th>real SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>45</td>\n",
       "      <td>CC(C)(Cc1ccc(2(cc(((F)((F)C(=O)Nc3ccccc3)cc1F</td>\n",
       "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.451613</td>\n",
       "      <td>31</td>\n",
       "      <td>C[C@@H]1CCN(c2cccn(CC3CC3)n2)n1</td>\n",
       "      <td>C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.510204</td>\n",
       "      <td>49</td>\n",
       "      <td>N#Cc1ccc(-c2c(C(=O)NCCCCCCCCCCCCccccccccccccccccc</td>\n",
       "      <td>N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.448980</td>\n",
       "      <td>49</td>\n",
       "      <td>CCOC(=O)[C@@H]1CCN(C(=O)c2ccc(-c3ccccccncCCCCCCC1</td>\n",
       "      <td>CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.679487</td>\n",
       "      <td>78</td>\n",
       "      <td>N#C1C(=O(CC(=O)NcccccccCcCCCCCCCCCCCCCCCCCCCCC...</td>\n",
       "      <td>N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>42</td>\n",
       "      <td>CC[NH+](C)CCCCCCCCCCCCCC@H]111cccccccccrcc</td>\n",
       "      <td>CC[NH+](CC)[C@](C)(CC)[C@H](O)c1cscc1Br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.459459</td>\n",
       "      <td>37</td>\n",
       "      <td>COc1ccc(C(=O)N(C)C[C@@H]((C)C)OCO)cc1</td>\n",
       "      <td>COc1ccc(C(=O)N(C)[C@@H](C)C/C(N)=N/O)cc1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>37</td>\n",
       "      <td>O=C(Nc1ncncc1[Nc1ccc(F)cc1)Nc1ncccc1F</td>\n",
       "      <td>O=C(Nc1nc[nH]n1)c1cccnc1Nc1cccc(F)c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>40</td>\n",
       "      <td>Cc1cc(/C=C/c2ccc((Brcccccccccccccccccccc</td>\n",
       "      <td>Cc1c(/C=N/c2cc(Br)ccn2)c(O)n2c(nc3ccccc32)c1C#N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.489362</td>\n",
       "      <td>47</td>\n",
       "      <td>C[C@@H]1CN(C(=O)c2ccc(Br)cc2C)C[C@@H]1CCC[NH3+]</td>\n",
       "      <td>C[C@@H]1CN(C(=O)c2cc(Br)cn2C)CC[C@H]1[NH3+]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.548387</td>\n",
       "      <td>62</td>\n",
       "      <td>CCOc1ccc(OCC(C)(CCCCCCCCCCCCCCCCC(CCccccccC(cC...</td>\n",
       "      <td>CCOc1ccc(OCC)c([C@H]2C(C#N)=C(N)N(c3ccccc3C(F)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.632653</td>\n",
       "      <td>49</td>\n",
       "      <td>Cc1ccc2c(SCCC@@H](C)C(=O)NCCCCCCCCCCCCcCcCcCcCcCc</td>\n",
       "      <td>Cc1ccc2nc(S[C@H](C)C(=O)NC3CCC(C)CC3)n(C)c(=O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>32</td>\n",
       "      <td>O=C(N1CCc2ccc(F)ccc2)c1)C(F)(F)F</td>\n",
       "      <td>O=C(N1CCc2c(F)ccc(F)c2C1)C1(O)Cc2ccccc2C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.423077</td>\n",
       "      <td>52</td>\n",
       "      <td>Cc1ccccc1C(=O)N1CCCCCCCCCCCCCCCCCccccccccCcCCC...</td>\n",
       "      <td>Cc1ccccc1C(=O)N1CCC2(CC1)C[C@H](c1ccccc1)C(=O)N2C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>50</td>\n",
       "      <td>CCCc1cc(NC(=O)CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...</td>\n",
       "      <td>CCCc1cc(NC(=O)CN2C(=O)NC3(CCC(C)CC3)C2=O)n(C)n1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ERROR rate  len elements  \\\n",
       "0     0.666667            45   \n",
       "1     0.451613            31   \n",
       "2     0.510204            49   \n",
       "3     0.448980            49   \n",
       "4     0.679487            78   \n",
       "5     0.500000            42   \n",
       "6     0.459459            37   \n",
       "7     0.621622            37   \n",
       "8     0.675000            40   \n",
       "9     0.489362            47   \n",
       "10    0.548387            62   \n",
       "11    0.632653            49   \n",
       "12    0.625000            32   \n",
       "13    0.423077            52   \n",
       "14    0.500000            50   \n",
       "\n",
       "                                       predict SMILES  \\\n",
       "0       CC(C)(Cc1ccc(2(cc(((F)((F)C(=O)Nc3ccccc3)cc1F   \n",
       "1                     C[C@@H]1CCN(c2cccn(CC3CC3)n2)n1   \n",
       "2   N#Cc1ccc(-c2c(C(=O)NCCCCCCCCCCCCccccccccccccccccc   \n",
       "3   CCOC(=O)[C@@H]1CCN(C(=O)c2ccc(-c3ccccccncCCCCCCC1   \n",
       "4   N#C1C(=O(CC(=O)NcccccccCcCCCCCCCCCCCCCCCCCCCCC...   \n",
       "5          CC[NH+](C)CCCCCCCCCCCCCC@H]111cccccccccrcc   \n",
       "6               COc1ccc(C(=O)N(C)C[C@@H]((C)C)OCO)cc1   \n",
       "7               O=C(Nc1ncncc1[Nc1ccc(F)cc1)Nc1ncccc1F   \n",
       "8            Cc1cc(/C=C/c2ccc((Brcccccccccccccccccccc   \n",
       "9     C[C@@H]1CN(C(=O)c2ccc(Br)cc2C)C[C@@H]1CCC[NH3+]   \n",
       "10  CCOc1ccc(OCC(C)(CCCCCCCCCCCCCCCCC(CCccccccC(cC...   \n",
       "11  Cc1ccc2c(SCCC@@H](C)C(=O)NCCCCCCCCCCCCcCcCcCcCcCc   \n",
       "12                   O=C(N1CCc2ccc(F)ccc2)c1)C(F)(F)F   \n",
       "13  Cc1ccccc1C(=O)N1CCCCCCCCCCCCCCCCCccccccccCcCCC...   \n",
       "14  CCCc1cc(NC(=O)CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...   \n",
       "\n",
       "                                          real SMILES  \n",
       "0             CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1  \n",
       "1        C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1  \n",
       "2   N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...  \n",
       "3   CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...  \n",
       "4   N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...  \n",
       "5             CC[NH+](CC)[C@](C)(CC)[C@H](O)c1cscc1Br  \n",
       "6           COc1ccc(C(=O)N(C)[C@@H](C)C/C(N)=N/O)cc1O  \n",
       "7                O=C(Nc1nc[nH]n1)c1cccnc1Nc1cccc(F)c1  \n",
       "8     Cc1c(/C=N/c2cc(Br)ccn2)c(O)n2c(nc3ccccc32)c1C#N  \n",
       "9         C[C@@H]1CN(C(=O)c2cc(Br)cn2C)CC[C@H]1[NH3+]  \n",
       "10  CCOc1ccc(OCC)c([C@H]2C(C#N)=C(N)N(c3ccccc3C(F)...  \n",
       "11  Cc1ccc2nc(S[C@H](C)C(=O)NC3CCC(C)CC3)n(C)c(=O)...  \n",
       "12          O=C(N1CCc2c(F)ccc(F)c2C1)C1(O)Cc2ccccc2C1  \n",
       "13  Cc1ccccc1C(=O)N1CCC2(CC1)C[C@H](c1ccccc1)C(=O)N2C  \n",
       "14    CCCc1cc(NC(=O)CN2C(=O)NC3(CCC(C)CC3)C2=O)n(C)n1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AERNN_pred_structure_dict_emb = statSMILES(encoder_zinc, decoder_zinc, pairs[:20])\n",
    "AERNN_pred_structure_train_df = pd.DataFrame(AERNN_pred_structure_dict_emb)\n",
    "AERNN_pred_structure_train_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.autograd import Variable\n",
    "from rdkit import Chem\n",
    "from deepchem.feat.one_hot import OneHotFeaturizer, zinc_charset\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSOS(arr):\n",
    "    arr = np.append(arr, np.zeros((arr.shape[0], 1)), axis=1)\n",
    "    arr = np.insert(arr, 0, 0, axis=0)\n",
    "    arr[0][-1] = 1\n",
    "    return arr\n",
    "\n",
    "def onehotSMILES(featurizer, df, property_s):\n",
    "    onehot_ID_list = []\n",
    "    onehot_error_ID_list = []\n",
    "    onehot_label_list = []\n",
    "    onehot_feature_sos_list = []\n",
    "    for index, label, mol in zip(list(df.index), list(df[property_s]), list(df['mols'])):\n",
    "        try:\n",
    "            feature = featurizer.featurize([mol])[0]\n",
    "            if feature.shape[0] > 120:\n",
    "                continue\n",
    "            onehot_ID_list.append(index)\n",
    "            onehot_label_list.append(label)\n",
    "        except:\n",
    "            onehot_error_ID_list.append(index)\n",
    "\n",
    "    onehot_feature_list = featurizer.featurize(df['mols'][onehot_ID_list])\n",
    "    print('---Finish OneHotFeaturizer---')\n",
    "    print('Length of whole data is {}. Length of valid data is {}'.format(len(df), len(onehot_feature_list)))\n",
    "\n",
    "    # Add SOS\n",
    "    for i, x in enumerate(onehot_feature_list):\n",
    "        onehot_feature_sos_list.append(addSOS(x))\n",
    "    onehot_feature_list = onehot_feature_sos_list\n",
    "    print('---Finish Add SOS---')\n",
    "\n",
    "    onehot_feature_list_np = np.asarray(onehot_feature_list, dtype=np.float32)\n",
    "    onehot_label_np = np.asarray(onehot_label_list, dtype=np.float32)\n",
    "    onehot_feature_torch = torch.from_numpy(onehot_feature_list_np)\n",
    "    onehot_feature_label_torch = torch.from_numpy(onehot_label_np)\n",
    "    return onehot_feature_torch, onehot_feature_label_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdkit load SMILES and structures\n",
    "dset_path = 'dataset'\n",
    "esol_dset_path = os.path.join(dset_path, 'ESOL')\n",
    "esol_dset = os.path.join(esol_dset_path, 'delaney-processed.csv')\n",
    "zinc_dset = os.path.join(dset_path, '250k_rndm_zinc_drugs_clean_3.csv')\n",
    "\n",
    "# ESOL Dataset\n",
    "esol_df = pd.DataFrame.from_csv(esol_dset)\n",
    "esol_solu_df = esol_df[['smiles', 'measured log solubility in mols per litre']]\n",
    "# esol_solu_df['smiles_with_token'] = 's' + esol_solu_df['smiles'] + 'e'\n",
    "esol_solu_df['mols'] = esol_solu_df.apply(lambda x: Chem.MolFromSmiles(x.smiles), axis=1)\n",
    "\n",
    "# VAE Dataset\n",
    "zinc_df = pd.DataFrame.from_csv(zinc_dset, index_col=None)\n",
    "zinc_df['mols'] = zinc_df.apply(lambda x: Chem.MolFromSmiles(x.smiles), axis=1)\n",
    "\n",
    "# ----------One hot SMILES----------\n",
    "featurizer_onehot = OneHotFeaturizer(zinc_charset, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_feature_torch, onehot_feature_label_torch = onehotSMILES(featurizer_onehot, esol_solu_df, 'measured log solubility in mols per litre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncRNN(nn.Module):\n",
    "    def __init__(self, input_dim, n_hidden, n_layers):\n",
    "        super(AutoEncRNNPred, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.enc_embedding = nn.Embedding(input_dim, n_hidden)\n",
    "        self.enc_rnn = nn.RNN(input_size=n_hidden, hidden_size=n_hidden, num_layers=n_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x, enc_hidden_state):\n",
    "        embedded = self.enc_embedding(x).view(1, 1, -1)\n",
    "        encoded, enc_hidden_state = self.enc_rnn(embedded, enc_hidden_state)\n",
    "        return encoded, enc_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecRNN(nn.Module):\n",
    "    def __init__(self, input_dim, n_hidden, n_layers, seq_len, output_dim, pred_dim):\n",
    "        super(AutoEncRNNPred, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.teacher_forcing_ratio = 0.8\n",
    "\n",
    "        self.dec_embedding = nn.Embedding(input_dim, n_hidden)\n",
    "        self.dec_rnn = nn.GRU(input_size=input_dim, hidden_size=n_hidden, num_layers=n_layers, batch_first=True)\n",
    "        self.dec_out = nn.Linear(n_hidden, input_dim)\n",
    "\n",
    "    def forward(self, encoded, hidden):\n",
    "        embedded = encoded\n",
    "        # embedded = self.dec_embedding(encoded).view(1, 1, -1)\n",
    "        # embedded = F.relu(embedded)\n",
    "        decoded, hidden = self.dec_rnn(embedded, hidden)\n",
    "        decoded = self.dec_out(decoded)\n",
    "#         decoded = self.log_softmax(decoded)\n",
    "        return decoded, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss_func_pred, loss_func_dec, epoch, model_status_dict):\n",
    "    model.train()\n",
    "    seq_len, self.n_hidden = model.seq_len, model.self.n_hidden\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target.reshape(-1, 1))\n",
    "        # print(target.shape, target.dtype)\n",
    "        \n",
    "        # one-hot(batch, seq_len, feature_size) to int(batch, 1, feature_size)\n",
    "        # _, data_feature_int = torch.max(data, 2)\n",
    "        data_feature_int = np.argmax(data, axis=2)\n",
    "        \n",
    "        encoded = torch.zeros(data_feature_int.shape[0], seq_len, n_hidden)\n",
    "        for k in range(seq_len):\n",
    "            encoded_out, enc_hidden_state = self.encoder(x[:, k], enc_hidden_state)\n",
    "            encoded[:, k] = encoded_out[:, 0]\n",
    "        \n",
    "        encode, decode, predict, h_state = model(data_feature_int, None, None, data)  # get output for every net\n",
    "        # h_state = h_state.data  # repack the hidden state, break the connection from last iteration\n",
    "\n",
    "        optimizer.zero_grad()  # clear gradients for next train\n",
    "        loss_pred = 0\n",
    "        # loss_pred = loss_func_pred(predict, target)\n",
    "        loss_dec = loss_func_dec(decode.transpose(1, 2), np.argmax(data, axis=2))\n",
    "        loss = loss_pred + loss_dec\n",
    "#         print('decode.transpose', decode.transpose(1,2))\n",
    "#         print('argmax', np.argmax(data, axis=2))\n",
    "        loss.backward()  # backpropagation, compute gradients\n",
    "        optimizer.step()  # apply gradients\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                loss.data.item()))\n",
    "            model_status_dict['Epoch'].append(epoch)\n",
    "            model_status_dict['Batch_idx'].append(batch_idx)\n",
    "            model_status_dict['Loss'].append(loss.data.item())\n",
    "    return model_status_dict\n",
    "\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    real_data = None\n",
    "    real_target = None\n",
    "    pred_data = None\n",
    "    pred_target =None\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in test_loader:\n",
    "            # one-hot(batch, seq_len, feature_size) to int(batch, 1, feature_size)\n",
    "            _, data_feature_int = torch.max(data, 2)\n",
    "            \n",
    "            encode, decode, predict, h_state = model(data_feature_int, None, None, data)  # get output for every net\n",
    "\n",
    "            data = data.data.numpy()\n",
    "            target = target.data.numpy().reshape(-1, 1)\n",
    "            real_data = data if real_data is None else np.concatenate((real_data, data))\n",
    "            real_target = target if real_target is None else np.concatenate((real_target, target))\n",
    "\n",
    "            y_data = decode.data.numpy()\n",
    "#             y_target = predict.data.numpy()\n",
    "            pred_data = y_data if pred_data is None else np.concatenate((pred_data, y_data))\n",
    "#             pred_target = y_target if pred_target is None else np.concatenate((pred_target, y_target))\n",
    "    return real_data, pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncRNNPred(nn.Module):\n",
    "    def __init__(self, input_dim, n_hidden, n_layers, seq_len, output_dim, pred_dim):\n",
    "        super(AutoEncRNNPred, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.index2word = {0: 'SOS', 1: 'EOS'}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "        self.teacher_forcing_ratio = 0.8\n",
    "\n",
    "        # Encode(RNN)\n",
    "        self.enc_embedding = nn.Embedding(input_dim, n_hidden)\n",
    "        self.enc_rnn = nn.RNN(input_size=n_hidden, hidden_size=n_hidden, num_layers=n_layers, batch_first=True)\n",
    "\n",
    "        # Predict\n",
    "#         self.enc_linear = nn.Linear(seq_len * n_hidden, output_dim)\n",
    "#         self.pred = nn.Linear(output_dim, pred_dim)\n",
    "\n",
    "        # Decode(RNN)\n",
    "        self.dec_embedding = nn.Embedding(input_dim, n_hidden)\n",
    "        \n",
    "        self.dec_linear = nn.Linear(seq_len * n_hidden, input_dim)\n",
    "        self.dec_rnn = nn.GRU(input_size=input_dim, hidden_size=n_hidden, num_layers=n_layers, batch_first=True)\n",
    "        self.dec_out = nn.Linear(n_hidden, input_dim)\n",
    "#         self.log_softmax = nn.LogSoftmax(dim=1) # NllLoss\n",
    "        \n",
    "    def encoder(self, input_vec, hidden):\n",
    "#         embedded = self.enc_embedding(input_vec)\n",
    "        embedded = self.enc_embedding(input_vec).view(input_vec.shape[0], 1, -1)\n",
    "        output = embedded\n",
    "        rnn_out, hidden = self.enc_rnn(output, hidden)\n",
    "        return rnn_out, hidden\n",
    "        \n",
    "    def decoder(self, encoded, hidden):\n",
    "        embedded = encoded\n",
    "        # embedded = self.dec_embedding(encoded).view(1, 1, -1)\n",
    "        # embedded = F.relu(embedded)\n",
    "        decoded, hidden = self.dec_rnn(embedded, hidden)\n",
    "        decoded = self.dec_out(decoded)\n",
    "#         decoded = self.log_softmax(decoded)\n",
    "        return decoded, hidden\n",
    "\n",
    "    def forward(self, x, enc_hidden_state, dec_hidden_state, targets):\n",
    "        encoded = torch.zeros(x.shape[0], self.seq_len, self.n_hidden)\n",
    "        for k in range(self.seq_len):\n",
    "            encoded_out, enc_hidden_state = self.encoder(x[:, k], enc_hidden_state)\n",
    "            encoded[:, k] = encoded_out[:, 0]\n",
    "        \n",
    "        decoded_output_on_k, predicted, dec_hidden_state = None, None, None\n",
    "        \n",
    "        dec_hidden_state = enc_hidden_state\n",
    "        decoded_input = torch.zeros(targets.shape[0], self.seq_len, self.input_dim)\n",
    "        decoded_input[:, 0, -1] = 1\n",
    "        \n",
    "#         encoded = encoded.view(-1, encoded.shape[1] * encoded.shape[2])\n",
    "#         decoded_input = self.dec_linear(encoded)\n",
    "#         decoded_input = decoded_input[:, None, :]\n",
    "#         decoded_input = decoded_input.repeat(1, self.seq_len, 1)\n",
    "    \n",
    "        # Teacher Forcing\n",
    "        use_teacher_forcing = True if random.random() < self.teacher_forcing_ratio else False\n",
    "#         use_teacher_forcing = False\n",
    "        for k in range(1, self.seq_len):\n",
    "            decoded_output_on_k, dec_hidden_state = self.decoder(decoded_input, dec_hidden_state)\n",
    "            if use_teacher_forcing:\n",
    "                decoded_input = torch.zeros(targets.shape[0], self.seq_len, self.input_dim)\n",
    "                decoded_input[:, :k, :] = targets[:, :k, :]\n",
    "            else:\n",
    "                decoded_input = decoded_output_on_k\n",
    "\n",
    "        return encoded, decoded_output_on_k, predicted, dec_hidden_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
